# LLM

## 模型相關論文

- [Training language models to follow instructions with human feedback](https://arxiv.org/pdf/2203.02155.pdf)
  - InstructGPT
  - OpenAI
- [OPT: Open Pre-trained Transformer Language Models](https://arxiv.org/pdf/2205.01068.pdf)
  - OPT
  - Meta
- [Scaling Instruction-Finetuned Language Models](https://arxiv.org/pdf/2210.11416.pdf)
  - Flan-T5/PaLM
  - Google
- [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/pdf/2211.05100.pdf)
  - BLOOM
  - BigScience
- [Galactica: A Large Language Model for Science](https://arxiv.org/pdf/2211.09085.pdf)
  - Galactica
  - Meta
- [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971.pdf)
  - LLaMA
  - Meta
- [Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data](https://arxiv.org/pdf/2304.01196v2.pdf)

## 演算法相關論文

- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf)
- [MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning](https://arxiv.org/pdf/2205.00445.pdf)
- [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629.pdf)
- [PAL: Program-aided Language Models](https://arxiv.org/pdf/2211.10435.pdf)
- [Multimodal Chain-of-Thought Reasoning in Language Models](https://arxiv.org/pdf/2302.00923.pdf)
- [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/pdf/2302.04761.pdf)
- [SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks](https://arxiv.org/pdf/2302.13939.pdf)
- [Goal Driven Discovery of Distributional Differences via Language Descriptions](https://arxiv.org/pdf/2302.14233.pdf)
- [Reward Design with Language Models](https://arxiv.org/pdf/2303.00001.pdf)
- [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/pdf/2303.17580.pdf)
- [Sparks of Artificial General Intelligence: Early experiments with GPT-4](https://arxiv.org/pdf/2303.12712.pdf)
- [Grounded Decoding: Guiding Text Generation with Grounded Models for Robot Control](https://grounded-decoding.github.io/)

## Repositories

- [Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)
- [JARVIS](https://github.com/microsoft/JARVIS)
- [visual-chatgpt](https://github.com/microsoft/visual-chatgpt)
- [Auto-GPT](https://github.com/Torantulino/Auto-GPT)
- [babyagi](https://github.com/yoheinakajima/babyagi)
- [vocode](https://github.com/vocodedev/vocode-python)
- [langflow](https://github.com/logspace-ai/langflow)
- [langchain-prefect](https://github.com/PrefectHQ/langchain-prefect)
- [langchain-visualizer](https://github.com/amosjyng/langchain-visualizer)
- [langchain-ui](https://github.com/haneyume/langchain-ui)
- [langchain-serve](https://github.com/haneyume/langchain-serve)
- [flux](https://github.com/transmissions11/flux)
- [Prompt Engineering Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
- [FlexGen](https://github.com/FMInference/FlexGen)
- [gpt4all](https://github.com/nomic-ai/gpt4all)
- [RWKV-LM](https://github.com/BlinkDL/RWKV-LM)
- [xturing](https://github.com/stochasticai/xturing)
- [chat-flow](https://github.com/prompt-engineering/chat-flow)
- [tabby](https://github.com/TabbyML/tabby)
- [openplayground](https://github.com/nat/openplayground)
- [OpenICL](https://github.com/Shark-NLP/OpenICL)
- [chatarena](https://github.com/chatarena/chatarena)
- [segment-anything-video](https://github.com/kadirnar/segment-anything-video)
- [BabyDORA](https://github.com/ttizze/BabyDORA)
- [Grounded-Segment-Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything)
- [AgentGPT](https://github.com/reworkd/AgentGPT)
- [yakGPT](https://github.com/yakGPT/yakGPT)
- [aicommits](https://github.com/Nutlope/aicommits)
- [EditAnything](https://github.com/sail-sg/EditAnything)
- [crustagi](https://github.com/lukaesch/crustagi)
- [ai-legion](https://github.com/eumemic/ai-legion)
- [GPTCache](https://github.com/zilliztech/GPTCache)
- [wolverine](https://github.com/biobootloader/wolverine)

## 文章

- [Learn Prompting](https://learnprompting.org/docs/intro)
- [何謂 Transformer 模型？](https://blogs.nvidia.com.tw/2022/06/21/what-is-a-transformer-model/)
- [The Transformer Architecture](https://d2l.ai/chapter_attention-mechanisms-and-transformers/transformer.html)
- [d2l](https://d2l.ai/)
- [Llama Hub](https://llamahub.ai/)

## Websites

- [OpenAI](https://openai.com/)
- [Hugging Face](https://huggingface.co/)
- [Papers With Code](https://paperswithcode.com/)
- [LangChain](https://python.langchain.com/en/latest/)
- [LangChainJs](https://js.langchain.com/docs/)
- [Vocode](https://docs.vocode.dev/welcome)
- [Runway](https://runwayml.com/)
- [Jina](https://jina.ai/)
- [Cohere](https://cohere.ai/)
- [Deepgram](https://deepgram.com/)
- [Futurepedia](https://www.futurepedia.io/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/zh)
- [ExplainThis](https://www.explainthis.io/zh-hant/chatgpt)
- [Chat with Open Large Language Models](https://chat.lmsys.org/)
- [Task-driven Autonomous Agent Utilizing GPT-4, Pinecone, and LangChain for Diverse Applications](https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/)

## Database for Vector Search

- [Chroma](https://docs.trychroma.com/)
- [Pinecone](https://www.pinecone.io/)
- [Weaviate](https://weaviate.io/)

## Code Examples

- [Text classification with Transformer](https://keras.io/examples/nlp/text_classification_with_transformer/)

## 知乎

- [五万字综述！Prompt-Tuning：深度解读一种新的微调范式](https://zhuanlan.zhihu.com/p/618871247)
- [实时软件生成 —— Prompt 编程能否打通低代码的最后一公里？](https://zhuanlan.zhihu.com/p/610865447)
- [无代码编程](https://zhuanlan.zhihu.com/p/61288928)
- [如何从浅入深理解 transformer？](https://www.zhihu.com/question/471328838/answer/2864224369)
- [ChatGPT：从描述世界到创造世界](https://zhuanlan.zhihu.com/p/619291742)
- [Meta 发布图像分割论文 Segment Anything，将给 CV 研究带来什么影响？](https://www.zhihu.com/question/593914819/answer/2971080467)
- [AI 研发提效的正确姿势：开源 LLM + LoRA](https://zhuanlan.zhihu.com/p/620236884)
